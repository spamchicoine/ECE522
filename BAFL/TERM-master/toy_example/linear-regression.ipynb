{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abline(a, b, label_, c=None):\n",
    "    \n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = a * x_vals + b\n",
    "    plt.plot(x_vals, y_vals, label=label_, color=c, zorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = 290\n",
    "num_outlier = 10\n",
    "total_samples = num_sample + num_outlier\n",
    "\n",
    "theta = [-1, 0.2]\n",
    "#X = np.random.random_sample(num_sample) * 0.5 \n",
    "X = np.random.normal(0, 0.5, num_sample)\n",
    "y = theta[0]*X + theta[1] \n",
    "\n",
    "y += np.random.normal(0, 0.1, num_sample)\n",
    "\n",
    "X_out = np.random.normal(-2, 0.5, num_outlier)\n",
    "y_out = np.random.normal(0, 0.5, num_outlier)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(X, y, s=2, label='the major cluster of data')\n",
    "plt.scatter(X_out, y_out, s=2, label=\"outliers\")\n",
    "abline(theta[0], theta[1], 'ground truth', \"red\")\n",
    "plt.legend()\n",
    "\n",
    "y = np.append(y, y_out)\n",
    "X = np.append(X, X_out)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 20000\n",
    "\n",
    "X = X.reshape((total_samples, 1))\n",
    "intercept = np.ones((X.shape[0], 1))\n",
    "X_concatenate = np.concatenate((X, intercept), axis=1)\n",
    "\n",
    "\n",
    "thetas=[]\n",
    "max_=[]\n",
    "min_=[]\n",
    "avg_=[]\n",
    "var_=[]\n",
    "ts=[]\n",
    "\n",
    "for t in np.arange(-10, 0, 0.2):\n",
    "    theta_hat = np.zeros(2)\n",
    "    for _ in range(iters):\n",
    "        y_pred = np.dot(X_concatenate, theta_hat)\n",
    "        error = (y-y_pred)**2\n",
    "        grad = np.dot(-1*X_concatenate.T, np.multiply(np.exp(t*error), 2 * (y-y_pred))) \n",
    "        loss_mean = np.sum(np.exp(t * error))\n",
    "        theta_hat = theta_hat - 0.01 * grad/loss_mean\n",
    "        \n",
    "    thetas.append([theta_hat[0], theta_hat[1]])\n",
    "    print(theta_hat)\n",
    "    \n",
    "    loss = error * 0.5\n",
    "    ts.append(t)\n",
    "    avg_.append(np.mean(loss))\n",
    "    max_.append(max(loss))\n",
    "    min_.append(min(loss))\n",
    "    var_.append(np.var(loss))\n",
    "    \n",
    "    print(\"t={}, max loss: {}, min loss: {}, avg loss: {}, variance: {}\".format(t, max(loss), min(loss), np.mean(loss), np.var(loss)))\n",
    "\n",
    "for t in np.arange(0, 10, 0.2):\n",
    "    theta_hat = np.zeros(2)\n",
    "    for _ in range(iters):\n",
    "        y_pred = np.dot(X_concatenate, theta_hat)\n",
    "        error = (y-y_pred)**2\n",
    "        grad = np.dot(-1*X_concatenate.T, np.multiply(np.exp(t*error), 2 * (y-y_pred))) \n",
    "        loss_mean = np.sum(np.exp(t * error))\n",
    "        theta_hat = theta_hat - 0.01 * grad/loss_mean\n",
    "        \n",
    "    thetas.append([theta_hat[0], theta_hat[1]])\n",
    "    print(theta_hat)\n",
    "    \n",
    "    loss = error * 0.5\n",
    "    ts.append(t)\n",
    "    avg_.append(np.mean(loss))\n",
    "    max_.append(max(loss))\n",
    "    min_.append(min(loss))\n",
    "    var_.append(np.var(loss))\n",
    "    \n",
    "    print(\"t={}, max loss: {}, min loss: {}, avg loss: {}, variance: {}\".format(t, max(loss), min(loss), np.mean(loss), np.var(loss)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pl\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "\n",
    "colors_positive = pl.cm.Reds(np.linspace(0,0.8, 50))\n",
    "colors_negative = pl.cm.Blues(np.linspace(0, 0.8, 50))\n",
    "\n",
    "plt.figure(figsize=(4, 3.5))\n",
    "\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "print(len(thetas))\n",
    "for i in range(len(thetas)):\n",
    "    if i > 50:\n",
    "        abline(thetas[i][0], thetas[i][1], None, c=colors_positive[min(int((i-50)*1.1), 39)])\n",
    "    elif i < 50:\n",
    "        abline(thetas[i][0], thetas[i][1], None, c=colors_negative[min(int((49-i)*3.2), 49)])\n",
    "\n",
    "\n",
    "plt.scatter(X, y, s=1, c='#8c564b', zorder=2)\n",
    "plt.scatter(X_out, y_out, s=3,  c='#8c564b', zorder=2)\n",
    "abline(thetas[50][0], thetas[50][1], None, c='#e377c2')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "ax.tick_params(color='#dddddd')\n",
    "ax.spines['bottom'].set_color('#dddddd')\n",
    "ax.spines['top'].set_color('#dddddd')\n",
    "ax.spines['right'].set_color('#dddddd')\n",
    "ax.spines['left'].set_color('#dddddd')\n",
    "    \n",
    "plt.xlim(-3.5, 2.5)\n",
    "plt.ylim(-1.2, 1.8)\n",
    "plt.title(\"linear regression\", fontsize=17)\n",
    "plt.xlabel(r'$x$', fontsize=17)\n",
    "plt.ylabel(r'$y$', fontsize=17)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"2-linear_regression.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
